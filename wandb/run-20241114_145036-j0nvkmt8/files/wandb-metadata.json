{
  "os": "Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17",
  "python": "3.10.4",
  "startedAt": "2024-11-14T06:50:36.414011Z",
  "args": [
    "--local_rank=0",
    "--max_len",
    "64000",
    "--dataset",
    "/mnt/petrelfs/tangzecheng/llm-data-exp-space-2/zecheng/transfer_data/Qwen_query_answer_gen",
    "--input_key",
    "instruction_str",
    "--output_key",
    "pred_str",
    "--train_batch_size",
    "64",
    "--micro_train_batch_size",
    "1",
    "--lora_rank",
    "32",
    "--apply_chat_template",
    "--pretrain",
    "meta-llama/Meta-Llama-3-8B-Instruct",
    "--save_path",
    "/mnt/petrelfs/tangzecheng/llm-data-exp-space-2/zecheng/remote_ckpt/model/llama3-8b-sft",
    "--ckpt_path",
    "/mnt/petrelfs/tangzecheng/llm-data-exp-space-2/zecheng/remote_ckpt/model/llama3-8b-sft",
    "--save_steps",
    "15",
    "--num_process",
    "2",
    "--logging_steps",
    "1",
    "--eval_steps",
    "-1",
    "--zero_stage",
    "3",
    "--max_epochs",
    "5",
    "--bf16",
    "--flash_attn",
    "--learning_rate",
    "5e-6",
    "--gradient_checkpointing",
    "--disable_fast_tokenizer",
    "--use_wandb=f81f2a236e712350a0ec153e02f43d1366c856a5",
    "--wandb_project=debug_openrlhf_train_sft",
    "--wandb_run_name=llama3-8b-sft-vanilla"
  ],
  "program": "/mnt/petrelfs/tangzecheng/MyRLHF/openrlhf/cli/train_sft_dev.py",
  "codePath": "openrlhf/cli/train_sft_dev.py",
  "git": {
    "remote": "https://gitlab.com/ZetangForward1/MyRLHF.git",
    "commit": "eab2408ddd5d9aa072376fda23981277ca7fcd62"
  },
  "email": "zecheng.tang@foxmail.com",
  "root": "/mnt/petrelfs/tangzecheng/MyRLHF",
  "host": "SH-IDC1-10-140-24-116",
  "username": "tangzecheng",
  "executable": "/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng_new/bin/python",
  "codePathLocal": "openrlhf/cli/train_sft_dev.py",
  "cpu_count": 128,
  "cpu_count_logical": 256,
  "gpu": "NVIDIA A100-SXM4-80GB",
  "gpu_count": 8,
  "disk": {
    "/": {
      "total": "772716625920",
      "used": "24918794240"
    }
  },
  "memory": {
    "total": "1081885822976"
  },
  "cpu": {
    "count": 128,
    "countLogical": 256
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    }
  ],
  "slurm": {
    "cluster_name": "cluster_sproject2",
    "conf": "/etc/slurm/slurm.conf",
    "cpus_on_node": "128",
    "distribution": "block",
    "gtids": "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15",
    "job_cpus_per_node_pack_group_0": "128",
    "job_gid": "200002796",
    "job_id": "4491050",
    "job_name": "bash",
    "job_nodelist": "SH-IDC1-10-140-24-116",
    "job_partition": "sproject2",
    "job_uid": "200002796",
    "job_user": "tangzecheng",
    "jobid": "4491050",
    "launch_node_ipaddr": "10.140.24.32",
    "localid": "0",
    "nnodes": "1",
    "nodeid": "0",
    "nodelist": "SH-IDC1-10-140-24-116",
    "nprocs": "16",
    "ntasks": "16",
    "prio_process": "0",
    "procid": "0",
    "pty_port": "40046",
    "pty_win_col": "274",
    "pty_win_row": "30",
    "srun_comm_host": "10.140.24.32",
    "srun_comm_port": "45131",
    "step_gpus": "0,1,2,3,4,5,6,7",
    "step_id": "3",
    "step_launcher_port": "45131",
    "step_nodelist": "SH-IDC1-10-140-24-116",
    "step_num_nodes": "1",
    "step_num_tasks": "16",
    "step_tasks_per_node": "16",
    "stepid": "3",
    "submit_dir": "/mnt/petrelfs/tangzecheng/MyRLHF",
    "submit_host": "SH-IDC1-10-140-24-32",
    "task_pid": "46244",
    "tasks_per_node": "16",
    "topology_addr": "SH-IDC1-10-140-24-116",
    "topology_addr_pattern": "node",
    "umask": "0002",
    "working_cluster": "cluster_sproject2:SH-IDC1-10-140-24-34:6817:9216:109"
  },
  "cudaVersion": "12.0"
}