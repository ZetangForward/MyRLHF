{
  "os": "Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17",
  "python": "3.10.4",
  "startedAt": "2024-11-10T18:59:32.142545Z",
  "args": [
    "--local_rank=0",
    "--max_len",
    "64000",
    "--dataset",
    "/mnt/petrelfs/tangzecheng/transfer_data/Qwen_query_answer_gen",
    "--input_key",
    "instruction_str",
    "--output_key",
    "pred_str",
    "--train_batch_size",
    "64",
    "--micro_train_batch_size",
    "1",
    "--lora_rank",
    "32",
    "--apply_chat_template",
    "--pretrain",
    "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "--save_path",
    "/mnt/petrelfs/tangzecheng/local_ckpt/checkpoint/model/Llama-3-8B-Instruct-128k-tool-sft",
    "--ckpt_path",
    "/mnt/petrelfs/tangzecheng/local_ckpt/checkpoint/opt/Llama-3-8B-Instruct-tool-sft",
    "--save_steps",
    "50",
    "--num_process",
    "20",
    "--logging_steps",
    "1",
    "--eval_steps",
    "-1",
    "--zero_stage",
    "3",
    "--max_epochs",
    "2",
    "--packing_samples",
    "--bf16",
    "--flash_attn",
    "--learning_rate",
    "5e-6",
    "--gradient_checkpointing",
    "--disable_fast_tokenizer",
    "--use_wandb=f81f2a236e712350a0ec153e02f43d1366c856a5",
    "--wandb_project=openrlhf_sft",
    "--wandb_run_name=Llama-3-8B-Instruct-80K-tool-sft-ring-2",
    "--ring_attn_size",
    "2"
  ],
  "program": "/mnt/petrelfs/tangzecheng/MyRLHF/openrlhf/cli/train_sft_dev.py",
  "codePath": "openrlhf/cli/train_sft_dev.py",
  "git": {
    "remote": "https://gitlab.com/ZetangForward1/MyRLHF.git",
    "commit": "549f90022ed0fe7ed9d2d2cc8f8c9c72198be940"
  },
  "email": "zecheng.tang@foxmail.com",
  "root": "/mnt/petrelfs/tangzecheng/MyRLHF",
  "host": "SH-IDC1-10-140-24-53",
  "username": "tangzecheng",
  "executable": "/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng_new/bin/python",
  "codePathLocal": "openrlhf/cli/train_sft_dev.py",
  "cpu_count": 128,
  "cpu_count_logical": 256,
  "gpu": "NVIDIA A100-SXM4-80GB",
  "gpu_count": 8,
  "disk": {
    "/": {
      "total": "772716625920",
      "used": "26991599616"
    }
  },
  "memory": {
    "total": "1081885798400"
  },
  "cpu": {
    "count": 128,
    "countLogical": 256
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    }
  ],
  "slurm": {
    "cluster_name": "cluster_sproject2",
    "conf": "/etc/slurm/slurm.conf",
    "cpus_on_node": "1",
    "gtids": "0",
    "job_account": "research",
    "job_cpus_per_node": "1",
    "job_gid": "200002796",
    "job_gpus": "0,1,2,3,4,5,6,7",
    "job_id": "4469331",
    "job_name": "test",
    "job_nodelist": "SH-IDC1-10-140-24-53",
    "job_num_nodes": "1",
    "job_partition": "sproject2",
    "job_qos": "normal",
    "job_uid": "200002796",
    "job_user": "tangzecheng",
    "jobid": "4469331",
    "localid": "0",
    "nnodes": "1",
    "node_aliases": "(null)",
    "nodeid": "0",
    "nodelist": "SH-IDC1-10-140-24-53",
    "nprocs": "1",
    "ntasks": "1",
    "ntasks_per_node": "1",
    "prio_process": "5",
    "procid": "0",
    "submit_dir": "/mnt/petrelfs/tangzecheng/MyRLHF",
    "submit_host": "SH-IDC1-10-140-24-32",
    "task_pid": "251184",
    "tasks_per_node": "1",
    "topology_addr": "SH-IDC1-10-140-24-53",
    "topology_addr_pattern": "node",
    "working_cluster": "cluster_sproject2:SH-IDC1-10-140-24-34:6817:9216:109"
  },
  "cudaVersion": "12.0"
}