[2024-10-24 17:28:51,464] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:29:39,123] [WARNING] [runner.py:212:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected VISIBLE_DEVICES=0,1,2,3,4,5,6,7 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2024-10-24 17:29:39,139] [INFO] [runner.py:585:main] cmd = /public/home/zecheng/anaconda3/envs/zecheng/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None openrlhf/cli/train_sft_dev.py --max_len 64000 --dataset /data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen --input_key instruction_str --output_key pred_str --train_batch_size 64 --micro_train_batch_size 2 --lora_rank 32 --apply_chat_template --pretrain /public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct --save_path /public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft --ckpt_path /public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft --save_steps 50 --num_process 32 --logging_steps 1 --eval_steps -1 --zero_stage 3 --max_epochs 3 --packing_samples --bf16 --flash_attn --learning_rate 5e-6 --gradient_checkpointing --use_tensorboard /public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard --disable_fast_tokenizer --ring_attn_size 2
[2024-10-24 17:29:41,566] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:29:44,173] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-10-24 17:29:44,174] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-10-24 17:29:44,174] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-10-24 17:29:44,174] [INFO] [launch.py:164:main] dist_world_size=8
[2024-10-24 17:29:44,174] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-10-24 17:29:44,175] [INFO] [launch.py:256:main] process 3363419 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=0', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:29:44,176] [INFO] [launch.py:256:main] process 3363420 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=1', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:29:44,177] [INFO] [launch.py:256:main] process 3363421 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=2', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:29:44,178] [INFO] [launch.py:256:main] process 3363422 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=3', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:29:44,179] [INFO] [launch.py:256:main] process 3363423 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=4', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:29:44,180] [INFO] [launch.py:256:main] process 3363424 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=5', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:29:44,180] [INFO] [launch.py:256:main] process 3363425 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=6', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:29:44,181] [INFO] [launch.py:256:main] process 3363426 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=7', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:30:12,049] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:30:12,078] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:30:12,166] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:30:12,178] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:30:12,183] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:30:12,187] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:30:12,189] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:30:12,190] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:30:21,982] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:30:21,982] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:30:21,983] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:30:21,983] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:30:21,983] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:30:22,003] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-10-24 17:30:21,983] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:30:21,983] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:30:21,983] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:30:25,222] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3363419
[2024-10-24 17:30:25,241] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3363420
[2024-10-24 17:30:25,241] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3363421
[2024-10-24 17:30:25,252] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3363422
[2024-10-24 17:30:25,262] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3363423
[2024-10-24 17:30:25,273] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3363424
[2024-10-24 17:30:25,285] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3363425
[2024-10-24 17:30:25,296] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3363426
[2024-10-24 17:30:25,306] [ERROR] [launch.py:325:sigkill_handler] ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=7', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2'] exits with return code = 1
