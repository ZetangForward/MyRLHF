[2024-10-24 17:33:31,368] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:33:37,015] [WARNING] [runner.py:212:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected VISIBLE_DEVICES=0,1,2,3,4,5,6,7 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2024-10-24 17:33:37,019] [INFO] [runner.py:585:main] cmd = /public/home/zecheng/anaconda3/envs/zecheng/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None openrlhf/cli/train_sft_dev.py --max_len 64000 --dataset /data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen --input_key instruction_str --output_key pred_str --train_batch_size 64 --micro_train_batch_size 2 --lora_rank 32 --apply_chat_template --pretrain /public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct --save_path /public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft --ckpt_path /public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft --save_steps 50 --num_process 32 --logging_steps 1 --eval_steps -1 --zero_stage 3 --max_epochs 3 --packing_samples --bf16 --flash_attn --learning_rate 5e-6 --gradient_checkpointing --use_tensorboard /public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard --disable_fast_tokenizer --ring_attn_size 2
[2024-10-24 17:33:39,431] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:33:42,504] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-10-24 17:33:42,506] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-10-24 17:33:42,506] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-10-24 17:33:42,506] [INFO] [launch.py:164:main] dist_world_size=8
[2024-10-24 17:33:42,506] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-10-24 17:33:42,507] [INFO] [launch.py:256:main] process 3368505 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=0', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:33:42,509] [INFO] [launch.py:256:main] process 3368506 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=1', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:33:42,510] [INFO] [launch.py:256:main] process 3368507 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=2', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:33:42,511] [INFO] [launch.py:256:main] process 3368508 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=3', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:33:42,512] [INFO] [launch.py:256:main] process 3368509 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=4', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:33:42,513] [INFO] [launch.py:256:main] process 3368510 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=5', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:33:42,514] [INFO] [launch.py:256:main] process 3368511 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=6', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:33:42,515] [INFO] [launch.py:256:main] process 3368512 spawned with command: ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=7', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2']
[2024-10-24 17:33:55,185] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:33:55,198] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:33:55,206] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:33:55,207] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:33:55,208] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:33:55,210] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:33:55,212] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:33:55,214] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-24 17:34:12,177] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:34:12,177] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:34:12,177] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:34:12,177] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:34:12,191] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-10-24 17:34:12,177] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:34:12,177] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:34:12,177] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-10-24 17:34:12,177] [INFO] [comm.py:652:init_distributed] cdb=None
dataset: /data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen
[2024-10-24 17:34:15,548] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3368505
[2024-10-24 17:34:15,565] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3368506
[2024-10-24 17:34:15,578] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3368507
[2024-10-24 17:34:15,590] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3368508
[2024-10-24 17:34:15,600] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3368509
[2024-10-24 17:34:15,611] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3368510
[2024-10-24 17:34:15,621] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3368511
[2024-10-24 17:34:15,632] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3368512
[2024-10-24 17:34:15,642] [ERROR] [launch.py:325:sigkill_handler] ['/public/home/zecheng/anaconda3/envs/zecheng/bin/python', '-u', 'openrlhf/cli/train_sft_dev.py', '--local_rank=7', '--max_len', '64000', '--dataset', '/data/zecheng/lcm_stack/dataset/training_data/Qwen_query_answer_gen', '--input_key', 'instruction_str', '--output_key', 'pred_str', '--train_batch_size', '64', '--micro_train_batch_size', '2', '--lora_rank', '32', '--apply_chat_template', '--pretrain', '/public/home/zecheng/workspace/hf_models/Meta-Llama-3.1-8B-Instruct', '--save_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/model/llama3.1-8b-tool-sft', '--ckpt_path', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025//checkpoint/opt/llama3.1-8b-tool-sft', '--save_steps', '50', '--num_process', '32', '--logging_steps', '1', '--eval_steps', '-1', '--zero_stage', '3', '--max_epochs', '3', '--packing_samples', '--bf16', '--flash_attn', '--learning_rate', '5e-6', '--gradient_checkpointing', '--use_tensorboard', '/public/home/zecheng/workspace/zecheng/ckpt/acl2025/checkpoint/tensorboard/llama3.1-8b-tool-sft/tensorboard', '--disable_fast_tokenizer', '--ring_attn_size', '2'] exits with return code = 1
