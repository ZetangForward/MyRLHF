SH-IDC1-10-140-24-43
20015
[2024-11-10 22:08:27,972] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-10 22:08:35,506] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected VISIBLE_DEVICES=0,1,2,3,4,5,6,7: setting --include=localhost:0,1,2,3,4,5,6,7
[2024-11-10 22:08:35,508] [INFO] [runner.py:607:main] cmd = /mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None fine-tune.py --report_to none --data_path data/belle_chat_ramdon_10k.json --model_name_or_path ../../Baichuan2-7B-Base --output_dir output --model_max_length 512 --num_train_epochs 4 --per_device_train_batch_size 16 --gradient_accumulation_steps 1 --save_strategy epoch --learning_rate 2e-5 --lr_scheduler_type constant --adam_beta1 0.9 --adam_beta2 0.98 --adam_epsilon 1e-8 --max_grad_norm 1.0 --weight_decay 1e-4 --warmup_ratio 0.0 --logging_steps 1 --gradient_checkpointing True --deepspeed ds_config.json --bf16 True --tf32 True
[2024-11-10 22:08:40,226] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-10 22:08:47,358] [INFO] [launch.py:139:main] 0 NCCL_SOCKET_IFNAME=eth0
[2024-11-10 22:08:47,360] [INFO] [launch.py:139:main] 0 NCCL_IB_HCA=mlx5_0,mlx5_2
[2024-11-10 22:08:47,361] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-11-10 22:08:47,362] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-11-10 22:08:47,363] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-11-10 22:08:47,364] [INFO] [launch.py:164:main] dist_world_size=8
[2024-11-10 22:08:47,365] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-11-10 22:08:47,375] [INFO] [launch.py:256:main] process 121696 spawned with command: ['/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python', '-u', 'fine-tune.py', '--local_rank=0', '--report_to', 'none', '--data_path', 'data/belle_chat_ramdon_10k.json', '--model_name_or_path', '../../Baichuan2-7B-Base', '--output_dir', 'output', '--model_max_length', '512', '--num_train_epochs', '4', '--per_device_train_batch_size', '16', '--gradient_accumulation_steps', '1', '--save_strategy', 'epoch', '--learning_rate', '2e-5', '--lr_scheduler_type', 'constant', '--adam_beta1', '0.9', '--adam_beta2', '0.98', '--adam_epsilon', '1e-8', '--max_grad_norm', '1.0', '--weight_decay', '1e-4', '--warmup_ratio', '0.0', '--logging_steps', '1', '--gradient_checkpointing', 'True', '--deepspeed', 'ds_config.json', '--bf16', 'True', '--tf32', 'True']
[2024-11-10 22:08:47,383] [INFO] [launch.py:256:main] process 121697 spawned with command: ['/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python', '-u', 'fine-tune.py', '--local_rank=1', '--report_to', 'none', '--data_path', 'data/belle_chat_ramdon_10k.json', '--model_name_or_path', '../../Baichuan2-7B-Base', '--output_dir', 'output', '--model_max_length', '512', '--num_train_epochs', '4', '--per_device_train_batch_size', '16', '--gradient_accumulation_steps', '1', '--save_strategy', 'epoch', '--learning_rate', '2e-5', '--lr_scheduler_type', 'constant', '--adam_beta1', '0.9', '--adam_beta2', '0.98', '--adam_epsilon', '1e-8', '--max_grad_norm', '1.0', '--weight_decay', '1e-4', '--warmup_ratio', '0.0', '--logging_steps', '1', '--gradient_checkpointing', 'True', '--deepspeed', 'ds_config.json', '--bf16', 'True', '--tf32', 'True']
[2024-11-10 22:08:47,392] [INFO] [launch.py:256:main] process 121698 spawned with command: ['/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python', '-u', 'fine-tune.py', '--local_rank=2', '--report_to', 'none', '--data_path', 'data/belle_chat_ramdon_10k.json', '--model_name_or_path', '../../Baichuan2-7B-Base', '--output_dir', 'output', '--model_max_length', '512', '--num_train_epochs', '4', '--per_device_train_batch_size', '16', '--gradient_accumulation_steps', '1', '--save_strategy', 'epoch', '--learning_rate', '2e-5', '--lr_scheduler_type', 'constant', '--adam_beta1', '0.9', '--adam_beta2', '0.98', '--adam_epsilon', '1e-8', '--max_grad_norm', '1.0', '--weight_decay', '1e-4', '--warmup_ratio', '0.0', '--logging_steps', '1', '--gradient_checkpointing', 'True', '--deepspeed', 'ds_config.json', '--bf16', 'True', '--tf32', 'True']
[2024-11-10 22:08:47,399] [INFO] [launch.py:256:main] process 121699 spawned with command: ['/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python', '-u', 'fine-tune.py', '--local_rank=3', '--report_to', 'none', '--data_path', 'data/belle_chat_ramdon_10k.json', '--model_name_or_path', '../../Baichuan2-7B-Base', '--output_dir', 'output', '--model_max_length', '512', '--num_train_epochs', '4', '--per_device_train_batch_size', '16', '--gradient_accumulation_steps', '1', '--save_strategy', 'epoch', '--learning_rate', '2e-5', '--lr_scheduler_type', 'constant', '--adam_beta1', '0.9', '--adam_beta2', '0.98', '--adam_epsilon', '1e-8', '--max_grad_norm', '1.0', '--weight_decay', '1e-4', '--warmup_ratio', '0.0', '--logging_steps', '1', '--gradient_checkpointing', 'True', '--deepspeed', 'ds_config.json', '--bf16', 'True', '--tf32', 'True']
[2024-11-10 22:08:47,406] [INFO] [launch.py:256:main] process 121700 spawned with command: ['/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python', '-u', 'fine-tune.py', '--local_rank=4', '--report_to', 'none', '--data_path', 'data/belle_chat_ramdon_10k.json', '--model_name_or_path', '../../Baichuan2-7B-Base', '--output_dir', 'output', '--model_max_length', '512', '--num_train_epochs', '4', '--per_device_train_batch_size', '16', '--gradient_accumulation_steps', '1', '--save_strategy', 'epoch', '--learning_rate', '2e-5', '--lr_scheduler_type', 'constant', '--adam_beta1', '0.9', '--adam_beta2', '0.98', '--adam_epsilon', '1e-8', '--max_grad_norm', '1.0', '--weight_decay', '1e-4', '--warmup_ratio', '0.0', '--logging_steps', '1', '--gradient_checkpointing', 'True', '--deepspeed', 'ds_config.json', '--bf16', 'True', '--tf32', 'True']
[2024-11-10 22:08:47,414] [INFO] [launch.py:256:main] process 121701 spawned with command: ['/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python', '-u', 'fine-tune.py', '--local_rank=5', '--report_to', 'none', '--data_path', 'data/belle_chat_ramdon_10k.json', '--model_name_or_path', '../../Baichuan2-7B-Base', '--output_dir', 'output', '--model_max_length', '512', '--num_train_epochs', '4', '--per_device_train_batch_size', '16', '--gradient_accumulation_steps', '1', '--save_strategy', 'epoch', '--learning_rate', '2e-5', '--lr_scheduler_type', 'constant', '--adam_beta1', '0.9', '--adam_beta2', '0.98', '--adam_epsilon', '1e-8', '--max_grad_norm', '1.0', '--weight_decay', '1e-4', '--warmup_ratio', '0.0', '--logging_steps', '1', '--gradient_checkpointing', 'True', '--deepspeed', 'ds_config.json', '--bf16', 'True', '--tf32', 'True']
[2024-11-10 22:08:47,424] [INFO] [launch.py:256:main] process 121702 spawned with command: ['/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python', '-u', 'fine-tune.py', '--local_rank=6', '--report_to', 'none', '--data_path', 'data/belle_chat_ramdon_10k.json', '--model_name_or_path', '../../Baichuan2-7B-Base', '--output_dir', 'output', '--model_max_length', '512', '--num_train_epochs', '4', '--per_device_train_batch_size', '16', '--gradient_accumulation_steps', '1', '--save_strategy', 'epoch', '--learning_rate', '2e-5', '--lr_scheduler_type', 'constant', '--adam_beta1', '0.9', '--adam_beta2', '0.98', '--adam_epsilon', '1e-8', '--max_grad_norm', '1.0', '--weight_decay', '1e-4', '--warmup_ratio', '0.0', '--logging_steps', '1', '--gradient_checkpointing', 'True', '--deepspeed', 'ds_config.json', '--bf16', 'True', '--tf32', 'True']
[2024-11-10 22:08:47,434] [INFO] [launch.py:256:main] process 121703 spawned with command: ['/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python', '-u', 'fine-tune.py', '--local_rank=7', '--report_to', 'none', '--data_path', 'data/belle_chat_ramdon_10k.json', '--model_name_or_path', '../../Baichuan2-7B-Base', '--output_dir', 'output', '--model_max_length', '512', '--num_train_epochs', '4', '--per_device_train_batch_size', '16', '--gradient_accumulation_steps', '1', '--save_strategy', 'epoch', '--learning_rate', '2e-5', '--lr_scheduler_type', 'constant', '--adam_beta1', '0.9', '--adam_beta2', '0.98', '--adam_epsilon', '1e-8', '--max_grad_norm', '1.0', '--weight_decay', '1e-4', '--warmup_ratio', '0.0', '--logging_steps', '1', '--gradient_checkpointing', 'True', '--deepspeed', 'ds_config.json', '--bf16', 'True', '--tf32', 'True']
/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python: can't open file '/mnt/petrelfs/tangzecheng/MyRLHF/fine-tune.py': [Errno 2] No such file or directory
/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python: can't open file '/mnt/petrelfs/tangzecheng/MyRLHF/fine-tune.py': [Errno 2] No such file or directory
/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python: can't open file '/mnt/petrelfs/tangzecheng/MyRLHF/fine-tune.py': [Errno 2] No such file or directory
/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python: can't open file '/mnt/petrelfs/tangzecheng/MyRLHF/fine-tune.py': [Errno 2] No such file or directory
/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python: can't open file '/mnt/petrelfs/tangzecheng/MyRLHF/fine-tune.py': [Errno 2] No such file or directory
/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python: can't open file '/mnt/petrelfs/tangzecheng/MyRLHF/fine-tune.py': [Errno 2] No such file or directory
/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python: can't open file '/mnt/petrelfs/tangzecheng/MyRLHF/fine-tune.py': [Errno 2] No such file or directory
/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python: can't open file '/mnt/petrelfs/tangzecheng/MyRLHF/fine-tune.py': [Errno 2] No such file or directory
[2024-11-10 22:08:48,437] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 121696
[2024-11-10 22:08:48,484] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 121697
[2024-11-10 22:08:48,522] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 121698
[2024-11-10 22:08:48,560] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 121699
[2024-11-10 22:08:48,597] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 121700
[2024-11-10 22:08:48,598] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 121701
[2024-11-10 22:08:48,635] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 121702
[2024-11-10 22:08:48,673] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 121703
[2024-11-10 22:08:48,710] [ERROR] [launch.py:325:sigkill_handler] ['/mnt/petrelfs/tangzecheng/anaconda3/envs/zecheng/bin/python', '-u', 'fine-tune.py', '--local_rank=7', '--report_to', 'none', '--data_path', 'data/belle_chat_ramdon_10k.json', '--model_name_or_path', '../../Baichuan2-7B-Base', '--output_dir', 'output', '--model_max_length', '512', '--num_train_epochs', '4', '--per_device_train_batch_size', '16', '--gradient_accumulation_steps', '1', '--save_strategy', 'epoch', '--learning_rate', '2e-5', '--lr_scheduler_type', 'constant', '--adam_beta1', '0.9', '--adam_beta2', '0.98', '--adam_epsilon', '1e-8', '--max_grad_norm', '1.0', '--weight_decay', '1e-4', '--warmup_ratio', '0.0', '--logging_steps', '1', '--gradient_checkpointing', 'True', '--deepspeed', 'ds_config.json', '--bf16', 'True', '--tf32', 'True'] exits with return code = 2
